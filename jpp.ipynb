{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from transform_output_format import get_4D_output, get_2D_output\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from utils import load_data_input\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHI,CLS,SZA,SAA,dates = load_data_input(\"/home/jambe/solar-forecasting/X_train_copernicus.npz\")\n",
    "y_train_csv = pd.read_csv('/home/jambe/solar-forecasting/y_train_zRvpCeO_nQsYtKN.csv')\n",
    "y_train_4D = get_4D_output(y_train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.concatenate([GHI,CLS,SZA,SAA], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train_4D, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(sequence):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        sequence (array(nb_examples,nb_img,81,81)): _description_\n",
    "    \"\"\"\n",
    "    nb_samples, nb_img, size1, size2 = sequence.shape\n",
    "    seq_swap = sequence.swapaxes(1,2).swapaxes(2,3)\n",
    "    return seq_swap.reshape((nb_samples*size1*size2,nb_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1236, 28, 81, 81)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_BT(n_estimators=50, lr=0.1, max_depth=4, subsample=0.5, min_samples_split = 0.05, max_features=0.5, n_jobs=-1, verbose=0):\n",
    "    model_basis = GradientBoostingRegressor(loss=\"ls\", learning_rate=lr, n_estimators=n_estimators,max_depth=max_depth, subsample=subsample, min_samples_split=min_samples_split, max_features=max_features, verbose=verbose)\n",
    "    model = MultiOutputRegressor(model_basis, n_jobs=n_jobs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3214836, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model= create_model_BT(n_estimators=50, max_depth=10, subsample=0.5, verbose=1)\n",
    "X_train_reshape = prepare_data(X_train[:,:,15:66,15:66])\n",
    "y_train_reshape = prepare_data(y_train[:])\n",
    "X_test_reshape = prepare_data(X_test[:,:,15:66,15:66])\n",
    "y_test_reshape = prepare_data(y_test[:])\n",
    "y_train_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57881.3071       12351.1569           10.31m\n",
      "         1       54369.8593       12249.6014           10.46m\n",
      "         1       54780.3195       12637.6317           10.50m\n",
      "         1       55449.4122       12170.4253           10.65m\n",
      "         2       44500.1108        9907.6035            9.96m\n",
      "         2       47782.0482       10039.9006            9.96m\n",
      "         2       44532.0218       10247.0468           10.06m\n",
      "         2       45569.1834        9878.8914           10.11m\n",
      "         3       36406.3410        8078.3637            9.48m\n",
      "         3       39638.1227        8161.0281            9.48m\n",
      "         3       36257.3031        8313.4722            9.57m\n",
      "         3       37523.4794        8027.6567            9.62m\n",
      "         4       29868.2189        6550.0679            9.03m\n",
      "         4       33011.1936        6639.5829            9.02m\n",
      "         4       29520.7004        6741.4148            9.09m\n",
      "         4       31039.4608        6520.3721            9.13m\n",
      "         5       24516.0498        5317.4240            8.58m\n",
      "         5       27548.6401        5432.5460            8.58m\n",
      "         5       24040.5438        5469.5102            8.64m\n",
      "         5       25734.9467        5288.5622            8.66m\n",
      "         6       20193.2357        4331.9333            8.18m\n",
      "         6       23115.1625        4424.1240            8.19m\n",
      "         6       19610.7913        4440.5160            8.24m\n",
      "         6       21446.6049        4294.2011            8.24m\n",
      "         7       16667.2833        3530.8195            7.80m\n",
      "         7       19500.9874        3615.3432            7.85m\n",
      "         7       16019.4499        3597.0158            7.86m\n",
      "         7       17912.4766        3530.3086            7.88m\n",
      "         8       13789.8633        2874.4862            7.38m\n",
      "         8       15014.4773        2883.8629            7.43m\n",
      "         8       16500.2662        3023.1422            7.43m\n",
      "         8       13079.6473        2932.2272            7.44m\n",
      "         9       11462.6052        2333.4029            6.94m\n",
      "         9       14036.6760        2450.2136            6.98m\n",
      "         9       10703.5057        2372.7180            6.99m\n",
      "         9       12704.0714        2343.1150            6.99m\n",
      "        10        9562.5526        1893.4996            6.52m\n",
      "        10       12077.5388        1949.2868            6.54m\n",
      "        10        8777.1738        1928.7141            6.56m\n",
      "        10       10768.6546        1913.1991            6.56m\n",
      "        20        4173.9148         280.9738            2.14m\n",
      "        20        2262.6912         252.2350            2.14m\n",
      "        20        3368.2194         259.8604            2.14m\n",
      "        20        1454.7872         243.1219            2.15m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=GradientBoostingRegressor(loss='ls', max_depth=5,\n",
       "                                                         n_estimators=25,\n",
       "                                                         subsample=0.5,\n",
       "                                                         verbose=1),\n",
       "                     n_jobs=-1)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.fit(X_train_reshape,y_train_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9666777406834202"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.score(X_test_reshape, y_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'boosted_trees_0.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('boosted_trees_0.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GHI_test,CLS_test,SZA_test,SAA_test,dates_test = load_data_input(\"/home/jambe/solar-forecasting/X_test_copernicus.npz\")\n",
    "X_test = np.concatenate([GHI_test,CLS_test,SZA_test,SAA_test], axis=1)\n",
    "X_test_reshape = prepare_data(X_test[:,:,15:66,15:66])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4788441, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_test_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = loaded_model.predict(X_test_reshape)\n",
    "#Â y_preds = y_predict.reshape(1841,4,51,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4788441, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y_predict.shape)\n",
    "y_predict = y_predict.reshape(1841, 51, 51, 4)\n",
    "y_predict = y_predict.swapaxes(2,3).swapaxes(1,2)\n",
    "y_preds_2D = get_2D_output(y_predict)\n",
    "y_preds_2D.to_csv('boosted_trees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}